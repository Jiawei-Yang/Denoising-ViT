# DVT: Denoising Vision Transformers


2024-01-19: We will release our denoiser checkpoints within two weeks.

2024-02-05: Feel free to check out the *preliminary* checkpoints available [here](https://drive.google.com/drive/folders/1ZwNs0oaW3mU5Dym6sRTo9s4_Uwm31fHj?usp=drive_link). These checkpoints have been denoised from 10k VOC samples and evaluated in the paper. We plan to update the instructions for using these checkpoints soon. For now, please refer to the video_generation.py script for an example of their usage. Currently, we are still working on checkpoints denoised from ImageNet, which we will share later.

------
This is the official code release for

[**Denoising Vision Transformers**](https://jiawei-yang.github.io/DenoisingViT/resources/paper.pdf).

by [Jiawei Yang](https://jiawei-yang.github.io/)&dagger;\*, [Katie Z Luo](https://www.cs.cornell.edu/~katieluo/)\*, [Jiefeng Li](https://jeffli.site/), [Kilian Q. Weinberger](https://www.cs.cornell.edu/~kilian/), [Yonglong Tian](https://people.csail.mit.edu/yonglong/), and [Yue Wang](https://yuewang.xyz/)

[Paper](https://jiawei-yang.github.io/DenoisingViT/resources/paper.pdf) | [Arxiv](https://arxiv.org/pdf/2401.02957.pdf) | [Project Page](https://jiawei-yang.github.io/DenoisingViT/)

\* equal technical contribution &dagger; project lead

![Figure](assets/teaser.png)

### Abstract
We delve into a nuanced but significant challenge inherent to Vision Transformers (ViTs): feature maps of these models exhibit grid-like artifacts, which detrimentally hurt the performance of ViTs in downstream tasks. Our investigations trace this fundamental issue down to the positional embeddings at the input stage. To address this, we propose a novel noise model, which is universally applicable to all ViTs. Specifically, the noise model dissects ViT outputs into three components: a semantics term free from noise artifacts and two artifact-related terms that are conditioned on pixel locations. Such a decomposition is achieved by enforcing cross-view feature consistency with neural fields. This per-image optimization process extracts artifact-free features from raw ViT outputs, providing clean ViT features for offline applications. Furthermore, we introduce a learnable denoiser to predict artifact-free features directly from unprocessed ViT outputs, capable of generalizing to unseen data without the need for per-image optimization. Our two-stage approach, which we term as Denoising Vision Transformers (DVT), does not require re-training existing pre-trained ViTs, and is immediately applicable to any Transformer-based architectures. We evaluate our method on a variety of representative ViTs (DINO, MAE, DeiT-III, EVA02, CLIP, DINOv2, DINOv2-reg). Extensive evaluations demonstrate that our DVT consistently and significantly improves existing state-of-the-art general-purpose models in semantic and geometric tasks across multiple datasets (e.g., +3.84 mIoU). We hope our study will encourage a re-evaluation of ViT design, especially regarding the naive use of positional embeddings.

#### TL;DR:
We identify crucial artifacts in ViTs caused by positional embeddings and propose a two-stage approach to remove these artifacts, which significantly improves the feature quality of different pre-trained ViTs.

### Citation
```
@article{yang2024denoising,
  author = {Jiawei Yang and Katie Z Luo and Jiefeng Li and Kilian Q Weinberger and Yonglong Tian and Yue Wang},
  title = {Denoising Vision Transformers},
  journal = {arXiv preprint arXiv:2401.02957},
  year = {2024},
}
```


### Installation

1. Create a conda environment.

```
conda create -n dvt python=3.9 -y
```

2. Activate the environment.

```
conda activate dvt
```

3. Install dependencies from requirements.txt.

```
pip install -r requirements.txt
```

4. Install `tiny-cuda-nn` manually:

```
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch
``````
If you encounter the error `nvcc fatal : Unsupported gpu architecture compute_89`, try the following command:

    
``` 
TCNN_CUDA_ARCHITECTURES=86 pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch
```

If you encounter the `error: parameter packs not expanded with ‘...’`, Refer to [this solution](https://github.com/NVlabs/instant-ngp/issues/119#issuecomment-1034701258) on GitHub.


### Data preparation

1. PASCAL-VOC 2007 and 2012:
Please download the PASCAL VOC07 and PASCAL VOC12 datasets ([link](http://host.robots.ox.ac.uk/pascal/VOC/)) and put the data in the folder `data`, e.g., 
```
mkdir -p data
cd data
wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar
tar -xf VOCtrainval_06-Nov-2007.tar
wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar
tar -xf VOCtrainval_11-May-2012.tar
``` 

In our experiments reported in the paper, we used the first 10,000 examples from `data/voc_train.txt` for stage-1 denoising. This text file was generated by gathering all JPG images from `data/VOC2007/JPEGImages` and `data/VOC2012/JPEGImages`, excluding the validation images, and then randomly shuffling them.

2. ADE20K:  [legacy, need to check]
Please download the [ADE20K dataset](https://groups.csail.mit.edu/vision/datasets/ADE20K/) and put the data in  `data/ADEChallengeData2016`.

3. NYU-D:
Please download the [NYU-depth dataset](PLACEHOLDER) and put the data in  `data/nyu`. Results are provided given the 2014 annotations following previous works. 

4. ImageNet (Optional):
    - Download the ImageNet dataset from <http://www.image-net.org/>
    - Extract data following the instructions at [here](https://gist.github.com/BIGBALLON/8a71d225eff18d88e469e6ea9b39cef4).
    - Put the data in `data/imagenet`.

### Run the code:
See `sample_scripts` for examples of running the code.

We provide some demo outputs in demo/demo_outputs. For example, this image shows our denoising results on a cat image:
![Figure](demo/demo_outputs/dinov2_base_cat.jpg)
From left to right, we show: (1) input crop, (2) raw DINOv2 base output, (3) Kmeans clustering of the raw output, (4) L2 feature norm of the raw output, (5) the similarity between the central patch and other patches in the raw output, (6) our denoised output, (7) Kmeans clustering of the denoised output, (8) L2 feature norm of the denoised output, (9) the similarity between the central patch and other patches in the denoised output, (10) the decomposed shared artifacts, (11) the L2 norm of the shared artifacts, (12) the ground-truth residual error, (13) the predicted residual term, and (13) the composition of the shared artifacts and the predicted residual term.

### Main Results and Checkpoints


#### VOC Evaluation Results

|                   |  mIoU |  aAcc |  mAcc | Logfile |
|-------------------|:-----:|:-----:|:-----:|:-------:|
| MAE               | 50.24 | 88.02 | 63.15 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch16_224.mae_voc.log)|
| MAE + DVT         | 50.53 | 88.06 | 63.29 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch16_224.mae_voc.log)|
| DINO              | 63.00 | 91.38 | 76.35 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch16_224.dino_voc.log)|
| DINO + DVT        | 66.22 | 92.41 | 78.14 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch16_224.dino_voc.log)|
| Registers         | 83.64 | 96.31 | 90.67 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch14_reg4_dinov2.lvd142m_voc.log)|
| Registers + DVT   | 84.50 | 96.56 | 91.45 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch14_reg4_dinov2.lvd142m_voc.log)|
| DeiT3             | 70.62 | 92.69 | 81.23 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/deit3_base_patch16_224.fb_in1k_voc.log)|
| DeiT3 + DVT       | 73.36 | 93.34 | 83.74 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/deit3_base_patch16_224.fb_in1k_voc.log)|
| EVA               | 71.52 | 92.76 | 82.95 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/eva02_base_patch16_clip_224.merged2b_voc.log)|
| EVA + DVT         | 73.15 | 93.43 | 83.55 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/eva02_base_patch16_clip_224.merged2b_voc.log)|
| CLIP              | 77.78 | 94.74 | 86.57 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch16_clip_384.laion2b_ft_in12k_in1k_voc.log)|
| CLIP + DVT        | 79.01 | 95.13 | 87.48 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch16_clip_384.laion2b_ft_in12k_in1k_voc.log)|
| DINOv2            | 83.60 | 96.30 | 90.82 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch14_dinov2.lvd142m_voc.log)|
| DINOv2 + DVT      | 84.84 | 96.67 | 91.70 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch14_dinov2.lvd142m_voc.log)|


#### ADE20K Evaluation Results

|                   |  mIoU |  aAcc |  mAcc | Logfile |
|-------------------|:-----:|:-----:|:-----:|:-------:|
| MAE               | 23.60 | 68.54 | 31.49 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch16_224.mae_ade20k.log)|
| MAE + DVT         | 23.62 | 68.58 | 31.25 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch16_224.mae_ade20k.log)|
| DINO              | 31.03 | 73.56 | 40.33 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch16_224.dino_ade20k.log)|
| DINO + DVT        | 32.40 | 74.53 | 42.01 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch16_224.dino_ade20k.log)|
| Registers         | 48.22 | 81.11 | 60.52 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch14_reg4_dinov2.lvd142m_ade20k.log)|
| Registers + DVT   | 49.34 | 81.94 | 61.70 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch14_reg4_dinov2.lvd142m_ade20k.log)|
| DeiT3             | 32.73 | 72.61 | 42.81 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/deit3_base_patch16_224.fb_in1k_ade20k.log)|
| DeiT3 + DVT       | 36.57 | 74.44 | 49.01 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/deit3_base_patch16_224.fb_in1k_ade20k.log)|
| EVA               | 37.45 | 72.78 | 49.74 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/eva02_base_patch16_clip_224.merged2b_ade20k.log)|
| EVA + DVT         | 37.87 | 75.02 | 49.81 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/eva02_base_patch16_clip_224.merged2b_ade20k.log)|
| CLIP              | 40.51 | 76.44 | 52.47 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch16_clip_384.laion2b_ft_in12k_in1k_ade20k.log)|
| CLIP + DVT        | 41.10 | 77.41 | 53.07 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch16_clip_384.laion2b_ft_in12k_in1k_ade20k.log)|
| DINOv2            | 47.29 | 80.84 | 59.18 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch14_dinov2.lvd142m_ade20k.log)|
| DINOv2 + DVT      | 48.66 | 81.89 | 60.24 |[log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch14_dinov2.lvd142m_ade20k.log)|



#### NYU-D Evaluation Results

|                   |  RMSE  |  Rel   | Logfile |
|-------------------|:------:|:------:|:---:|
| MAE               | 0.6695 | 0.2334 | [log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch16_224.mae_nyu.log)|
| MAE + DVT         | 0.7080 | 0.2560 | [log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch16_224.mae_nyu.log)|
| DINO              | 0.5832 | 0.1701 | [log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch16_224.dino_nyu.log)|
| DINO + DVT        | 0.5780 | 0.1731 | [log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch16_224.dino_nyu.log)|
| Registers         | 0.3969 | 0.1190 | [log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch14_reg4_dinov2.lvd142m_nyu.log)|
| Registers + DVT   | 0.3880 | 0.1157 | [log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch14_reg4_dinov2.lvd142m_nyu.log)|
| DeiT3             |  0.588 | 0.1788 | [log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/deit3_base_patch16_224.fb_in1k_nyu.log)|
| DeiT3 + DVT       | 0.5891 | 0.1802 | [log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/deit3_base_patch16_224.fb_in1k_nyu.log)|
| EVA               | 0.6446 | 0.1989 | [log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/eva02_base_patch16_clip_224.merged2b_nyu.log)|
| EVA + DVT         | 0.6243 | 0.1964 | [log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/eva02_base_patch16_clip_224.merged2b_nyu.log)|
| CLIP              | 0.5598 | 0.1679 | [log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch16_clip_384.laion2b_ft_in12k_in1k_nyu.log)|
| CLIP + DVT        | 0.5591 | 0.1667 | [log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch16_clip_384.laion2b_ft_in12k_in1k_nyu.log)|
| DINOv2            | 0.4034 | 0.1238 | [log](https://jiawei-yang.github.io/DenoisingViT/logs/baselines/vit_base_patch14_dinov2.lvd142m_nyu.log)|
| DINOv2 + DVT      | 0.3943 | 0.1200 | [log](https://jiawei-yang.github.io/DenoisingViT/logs/dvt/vit_base_patch14_dinov2.lvd142m_nyu.log)|

#### Denoiser Checkpoints

[ ] To be released.
