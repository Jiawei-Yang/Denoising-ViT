import os
import os.path as osp
import warnings
from collections import OrderedDict
from functools import reduce
from logging import raiseExceptions

import mmcv
import numpy as np
import torch
from mmcv.utils import print_log
from mmseg.utils import get_root_logger
from PIL import Image
from prettytable import PrettyTable
from torch.utils.data import Dataset

from evaluation.depth.core import eval_metrics, metrics, pre_eval_to_metrics
from evaluation.depth.datasets.builder import DATASETS
from evaluation.depth.datasets.pipelines import Compose
from evaluation.depth.ops import resize


@DATASETS.register_module()
class CustomDepthDataset(Dataset):
    """Custom dataset for supervised monocular depth esitmation.
    An example of file structure. is as followed.
    .. code-block:: none
        ├── data
        │   ├── custom
        │   │   ├── train
        │   │   │   ├── rgb
        │   │   │   │   ├── 0.xxx
        │   │   │   │   ├── 1.xxx
        │   │   │   │   ├── 2.xxx
        │   │   │   ├── depth
        │   │   │   │   ├── 0.xxx
        │   │   │   │   ├── 1.xxx
        │   │   │   │   ├── 2.xxx
        │   │   ├── val
        │   │   │   ...
        │   │   │   ...

    Args:
        pipeline (list[dict]): Processing pipeline
        img_dir (str): Path to image directory
        data_root (str, optional): Data root for img_dir.
        test_mode (bool): test_mode=True
        min_depth=1e-3: Default min depth value.
        max_depth=10: Default max depth value.
    """

    def __init__(
        self,
        pipeline,
        data_root,
        test_mode=True,
        min_depth=1e-3,
        max_depth=10,
        depth_scale=1,
    ):
        self.pipeline = Compose(pipeline)
        self.img_path = os.path.join(data_root, "rgb")
        self.depth_path = os.path.join(data_root, "depth")
        self.test_mode = test_mode
        self.min_depth = min_depth
        self.max_depth = max_depth
        self.depth_scale = depth_scale

        # load annotations
        self.img_infos = self.load_annotations(self.img_path, self.depth_path)

    def __len__(self):
        """Total number of samples of data."""
        return len(self.img_infos)

    def load_annotations(self, img_dir, depth_dir):
        """Load annotation from directory.
        Args:
            img_dir (str): Path to image directory. Load all the images under the root.
        Returns:
            list[dict]: All image info of dataset.
        """

        img_infos = []

        imgs = os.listdir(img_dir)
        imgs.sort()

        if self.test_mode is not True:
            depths = os.listdir(depth_dir)
            depths.sort()

            for img, depth in zip(imgs, depths):
                img_info = dict()
                img_info["filename"] = img
                img_info["ann"] = dict(depth_map=depth)
                img_infos.append(img_info)

        else:
            for img in imgs:
                img_info = dict()
                img_info["filename"] = img
                img_infos.append(img_info)

        # github issue:: make sure the same order
        img_infos = sorted(img_infos, key=lambda x: x["filename"])
        print_log(f"Loaded {len(img_infos)} images.", logger=get_root_logger())

        return img_infos

    def pre_pipeline(self, results):
        """Prepare results dict for pipeline."""
        results["depth_fields"] = []
        results["img_prefix"] = self.img_path
        results["depth_prefix"] = self.depth_path
        results["depth_scale"] = self.depth_scale

    def __getitem__(self, idx):
        """Get training/test data after pipeline.
        Args:
            idx (int): Index of data.
        Returns:
            dict: Training/test data (with annotation if `test_mode` is set
                False).
        """
        if self.test_mode:
            return self.prepare_test_img(idx)
        else:
            return self.prepare_train_img(idx)

    def prepare_train_img(self, idx):
        """Get training data and annotations after pipeline.
        Args:
            idx (int): Index of data.
        Returns:
            dict: Training data and annotation after pipeline with new keys
                introduced by pipeline.
        """

        img_info = self.img_infos[idx]
        ann_info = self.get_ann_info(idx)
        results = dict(img_info=img_info, ann_info=ann_info)
        self.pre_pipeline(results)
        return self.pipeline(results)

    def prepare_test_img(self, idx):
        """Get testing data after pipeline.
        Args:
            idx (int): Index of data.
        Returns:
            dict: Testing data after pipeline with new keys introduced by
                pipeline.
        """

        img_info = self.img_infos[idx]
        results = dict(img_info=img_info)
        self.pre_pipeline(results)
        return self.pipeline(results)

    def get_ann_info(self, idx):
        """Get annotation by index.
        Args:
            idx (int): Index of data.
        Returns:
            dict: Annotation info of specified index.
        """

        return self.img_infos[idx]["ann"]

    # waiting to be done
    def format_results(self, results, imgfile_prefix=None, indices=None, **kwargs):
        """Place holder to format result to dataset specific output."""
        results[0] = (
            results[0] * self.depth_scale
        )  # Do not convert to np.uint16 for ensembling. # .astype(np.uint16)
        return results

    # design your own evaluation pipeline
    def pre_eval(self, preds, indices):
        pass

    def evaluate(self, results, metric="eigen", logger=None, **kwargs):
        pass
